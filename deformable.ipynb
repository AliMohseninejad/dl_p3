{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretic Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In normal CNNs, the grid sampling is fixed.\n",
    "The receptive field of a convolutional layer is defined by a regular grid of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deformable convolutional layers allows the sampling grid to be adjusted according to the learned offsets.\n",
    "They have an additional offset (Which is laearnable) for each sampling point in the kernel.\n",
    "This allows the layer to handle spatial transformations, such as object deformations, rotations, scalings, ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is done with the help of learnable offsets in the layer. during the training phase, these parameters are learned and adjusted so that the transformations in the input are taken care of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal convolutional layers have fixed receptive fields which means they can't adapt to variations in object sizes, shapes, or rotations. So, they might fail to capture the entire object when it's deformed or rotated significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deformable convolution layers include additional convolutional layers dedicated to predicting the offsets. These modules take the feature maps from the previous layers as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset() -> (list, list):\n",
    "    \"\"\"\n",
    "        This function returns the trainset and testset of the CIFAR10 dataset\n",
    "    \"\"\"\n",
    "\n",
    "    generator1 = torch.Generator().manual_seed(42)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset_all = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    testset_all = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # Filter the dataset to include only 'plane' and 'car' classes\n",
    "    classes_of_interest = [0, 1] # plane, automobile\n",
    "    train_dataset = [item for i, item in enumerate(trainset_all) if trainset_all.targets[i] in classes_of_interest]\n",
    "    test_dataset = [item for i, item in enumerate(testset_all) if testset_all.targets[i] in classes_of_interest]\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def separate_train_val(trainset: list, val_ratio = 0.2) -> (list, list):\n",
    "    \"\"\"\n",
    "        This function separates the train and validation sets with the given ratio\n",
    "    \"\"\"\n",
    "\n",
    "    validation_size = int(val_ratio*len(trainset))\n",
    "    train_size = len(trainset) - validation_size\n",
    "    train_dataset, val_dataset = random_split(trainset, [train_size, validation_size])\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def create_dataloaders(train_dataset, val_dataset, test_dataset):\n",
    "    \"\"\"\n",
    "        This function creates the dataloaders if the input is not None\n",
    "    \"\"\"\n",
    "    if train_dataset is not None:\n",
    "        train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    else:\n",
    "        train_loader = None\n",
    "    if val_dataset is not None:\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "    else:\n",
    "        val_loader = None\n",
    "    if test_dataset is not None:\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    else:\n",
    "        test_loader = None\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs, optimizer, loss_function) -> (list, list, list, list):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    train_loss_values = []\n",
    "    train_accuracy_values = []\n",
    "    val_loss_values = []\n",
    "    val_accuracy_values = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            # print(outputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate training loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_loader)\n",
    "        epoch_train_accuracy = correct / total\n",
    "\n",
    "        train_loss_values.append(epoch_train_loss)\n",
    "        train_accuracy_values.append(epoch_train_accuracy)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], \"\n",
    "            f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
    "            f\"Train Accuracy: {100 * epoch_train_accuracy:.2f}%\")\n",
    "\n",
    "        if val_loader is not None:\n",
    "\n",
    "            model.eval()\n",
    "            val_running_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for val_data in val_loader:\n",
    "                    val_inputs, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                    val_outputs = model(val_inputs)\n",
    "                    val_loss = loss_function(val_outputs, val_labels)\n",
    "                    val_running_loss += val_loss.item()\n",
    "                    _, val_predicted = val_outputs.max(1)\n",
    "                    val_total += val_labels.size(0)\n",
    "                    val_correct += val_predicted.eq(val_labels).sum().item()\n",
    "\n",
    "            epoch_val_loss = val_running_loss / len(val_loader)\n",
    "            epoch_val_accuracy = val_correct / val_total\n",
    "\n",
    "            val_loss_values.append(epoch_val_loss)\n",
    "            val_accuracy_values.append(epoch_val_accuracy)\n",
    "\n",
    "            print(f\"Validation Loss: {epoch_val_loss:.4f}, \"\n",
    "                f\"Validation Accuracy: {100 * epoch_val_accuracy:.2f}%\")\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "\n",
    "    return train_loss_values, train_accuracy_values, val_loss_values, val_accuracy_values\n",
    "\n",
    "\n",
    "def test(model, test_loader) -> float:\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_data in test_loader:\n",
    "            test_inputs, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "            test_outputs = model(test_inputs)\n",
    "            _, test_predicted = test_outputs.max(1)\n",
    "            test_total += test_labels.size(0)\n",
    "            test_correct += test_predicted.eq(test_labels).sum().item()\n",
    "\n",
    "    test_accuracy = test_correct / test_total\n",
    "    print(f\"Test Accuracy: {100 * test_accuracy:.2f}%\")\n",
    "    return test_accuracy\n",
    "\n",
    "\n",
    "def plot_results(train_loss_values, train_accuracy_values, val_loss_values, val_accuracy_values):\n",
    "\n",
    "    epochs = 60\n",
    "    # Plotting accuracy and loss per epoch\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plotting training and validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, epochs + 1), train_loss_values, label='Training Loss')\n",
    "    if val_loss_values is not None:\n",
    "        plt.plot(range(1, epochs + 1), val_loss_values, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss per Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plotting training and validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epochs + 1), train_accuracy_values, label='Training Accuracy')\n",
    "    if val_accuracy_values is not None:\n",
    "        plt.plot(range(1, epochs + 1), val_accuracy_values, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy per Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "def save_model(model, filename):\n",
    "    drive.mount('/content/drive')\n",
    "    torch.save(model.state_dict(), f'/content/drive/MyDrive/DeepHW/ProblemSet3/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 5 is not equal to len(dims) = 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, input_channels, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mdeformable_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Courses/deep_learning/hw/deep_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 56\u001b[0m, in \u001b[0;36mDeformableConv2D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m grid_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m grid_y \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(height \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Reshape grid\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Adjust the grid reshaping part\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Adjust the grid creation\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m grid \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Perform sampling using grid_sample\u001b[39;00m\n\u001b[1;32m     59\u001b[0m sampled_features \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mgrid_sample(x, grid, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 5 is not equal to len(dims) = 4"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DeformableConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(DeformableConv2D, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        # Regular convolutional layer weights\n",
    "        self.conv_weights = nn.Parameter(torch.Tensor(out_channels, in_channels, kernel_size, kernel_size))\n",
    "        nn.init.kaiming_normal_(self.conv_weights, mode='fan_out', nonlinearity='relu')\n",
    "        \n",
    "        # Offset prediction layer\n",
    "        self.offset_conv = nn.Conv2d(in_channels, 2 * kernel_size * kernel_size, \n",
    "                                     kernel_size=3, \n",
    "                                     stride=stride, \n",
    "                                     padding=padding)\n",
    "        \n",
    "        nn.init.constant_(self.offset_conv.weight, 0)\n",
    "        nn.init.constant_(self.offset_conv.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, height, width = x.size()\n",
    "        \n",
    "        # Predict offsets\n",
    "        offsets = self.offset_conv(x)\n",
    "        \n",
    "        # Reshape offsets to have separate dimensions for x and y offsets\n",
    "        offsets = offsets.view(batch_size, 2, self.kernel_size * self.kernel_size, height, width)\n",
    "        offsets_x, offsets_y = torch.split(offsets, 1, dim=1)\n",
    "        # Adjust the offset handling and grid generation part\n",
    "        offsets_x = offsets_x.squeeze(1).view(batch_size, self.kernel_size * self.kernel_size, height, width)\n",
    "        offsets_y = offsets_y.squeeze(1).view(batch_size, self.kernel_size * self.kernel_size, height, width)\n",
    "\n",
    "        # Generate sampling grid\n",
    "        grid_y, grid_x = torch.meshgrid(torch.arange(height), torch.arange(width))\n",
    "        grid_x = grid_x.type_as(x).view(1, 1, height, width).expand(batch_size, -1, -1, -1)\n",
    "        grid_y = grid_y.type_as(x).view(1, 1, height, width).expand(batch_size, -1, -1, -1)\n",
    "\n",
    "        # Add offsets to the grid\n",
    "        grid_x = grid_x + offsets_x\n",
    "        grid_y = grid_y + offsets_y\n",
    "\n",
    "        # Normalize grid to [-1, 1]\n",
    "        grid_x = 2 * grid_x / max(width - 1, 1) - 1\n",
    "        grid_y = 2 * grid_y / max(height - 1, 1) - 1\n",
    "\n",
    "        # Reshape grid\n",
    "        # Adjust the grid reshaping part\n",
    "        # Adjust the grid creation\n",
    "        grid = torch.stack((grid_x, grid_y), dim=-1).permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "        # Perform sampling using grid_sample\n",
    "        sampled_features = F.grid_sample(x, grid, align_corners=True)\n",
    "\n",
    "\n",
    "        \n",
    "        # Perform convolution using the sampled features and convolutional weights\n",
    "        output = F.conv2d(sampled_features, self.conv_weights, stride=self.stride, padding=self.padding)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Example usage:\n",
    "input_channels = 3\n",
    "output_channels = 64\n",
    "kernel_size = 3\n",
    "padding = 1\n",
    "\n",
    "# Create an instance of DeformableConv2D\n",
    "deformable_conv = DeformableConv2D(input_channels, output_channels, kernel_size, padding=padding)\n",
    "\n",
    "# Dummy input\n",
    "dummy_input = torch.randn(1, input_channels, 32, 32)\n",
    "\n",
    "# Forward pass\n",
    "output = deformable_conv(dummy_input)\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
